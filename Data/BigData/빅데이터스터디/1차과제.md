

### 1. Yarn과 MR(Map Reduce)의 차이

#### Hadoop 1.0
Hadoop 1.0은 HDFS와 Map Redue으로 구성.
[Map Reduce](#mapreduce)는 HDFS로 부터 데이터를 읽어와 key-value 형태로 데이터를 변형 후 원하는 결과값을 연산하는 과정을 수행한다. 이 과정에서 사용되는 resource들을 관리하고 스케쥴링 하는 역할도 수행했다. 두 가지의 일을 동시에 처리하다 보니 Map Reduce의 처리속도를 높일 수 없었다.
<br></br>

#### Haddop 2.0
Hadoop 2.0에서는 위에서 설명한 연산과정과 resource관리를 분리.
Resource 관리 → YARN (Map Reduce 2.0이라고도 불림)
Data Processing → 다양한 플랫폼 지원 (Map Reduce 포함)

![hadoop1.0 vs hadoop2.0](https://t1.daumcdn.net/cfile/tistory/22704C4853DF17AE1B)
--- 
<br></br>
### 2. Spark와 Yarn
* Spark와 Hadoop

    ||동작원리|
    |------|:---:|
    |Hadoop|디스크 기반의 MapReduce 방식|
    |Spark|메모리 기반의 MapReduce 방식|

    → 데이터의 용량이 메모리보다 크지 않은 경우, Spark의 속도가 훨씬 빠르다. 따라서 최근 Spark에 대한 수요가 증가하고 있다.

* Hadoop 2.0 에서 Spark 적용

    Yarn을 도입해서 Hadoop 2.0에서는 전통적인 MR application 뿐만 아니라 다양한 applicaition이 공존할 수 있게된다. 따라서 Yarn위에서 Spark를 사용할 수 있다.

    *(V1.0에서는 MR이 자원을 관리했기 때문에 반드시 이 구조를 지켜야 했지만 V2.0에서는 Yarn이 MR의 역할을 분담해 다양한 application이 올라갈 수 있는 환경이 구축된 것이라고 생각한다. Yarn이 없었으면 Hadoop system에서 spark와 같은 새로운 appliction의 사용은 어려웠을 것 같다)*

![spark와 Yarn](https://incredible.ai/assets/posts/Spark-Cluster/cluster_deployment_mode.png)
<br></br>
====
<br></br>

### 3. Thrift란
* Thrift?
    
    페이스북에서 개발한 [RPC framwork](#RPC), 현재 OpenSource Apache Project로 등록되어 있다. 20200206 기준 0.13.0 version.
    (Google RPC framework → <b>gRPC</b>)


* RPC(Remote Procedure Call)란<a id="RPC"></a>?

    client ↔ server 통신을 위해 등장한 통신 방법이다. 서로 떨어져 있는 두 기기간에 통신을 하기 위해서는 Network를 통해야 하는데, RPC를 사용하게 되면 개발자는 이부분에 대해서는 신경쓰지 않아도 된다. client에서는 server에 저장된 함수를 호출한다.(= 원격의 프로그램을 로컬의 함수호출처럼 사용할 수 있음) IDL(Interface Definition Language)를 사용해 둘 사이의 통신 규약을 정의한다. 

    *(IDL을 사용함으로써 분산된 서버에 종속되지 않고 연결을 가능하도록 함)*

    ![RPC Architecture](https://mindock.github.io/assets/images/RPC_concept.png)

* 대표적인 Client-server 통신 Rest vs RPC

    ||장점|단점|
    |:---:|:---:|:---:|
    |RPC|언어에 대한 종속성이 낮음, 프로세스간 통신이 쉽게 구현 가능|호출 실행과 반환시간이 보장되지 않음|
    |Rest|높은 개발 생산성,학습시간이 짧음|표준이 명확하지 않아 프로젝트 내에서 URI, return 방식 등 규칙을 정하고 이를 관리하는 Document가 필요(자동으로 Document생성해주는 오픈소스 존재 ex.swagger)|

###### *+RPC개발 경험 만들기!*

<br></br>
====
<br></br>

#### 참고
#### MapReduce 동작 과정<a id="mapreduce"></a>
1. Map        
입력데이터(정형/반정형/비정형)를 Key-value 데이터로 바꿔주는 과정 (Mapper가 이를 수행)

2. Combiner
Mapper를 통해 생성된 데이터들을 Key를 기준으로 데이터를 병합함 (데이터의 양을 줄여 Network bottle-nect 현상을 줄여줄 수 있는 과정)

3. Suffle, Partitioner
Combiner에 의해 병합된 각각의 데이터들을 처리할 Node로 보내주는 역할 (Partitioner이 suffle을 수행함)

4. Sort
Reduce에서 더욱 효율적으로 Computing하기 위해 정렬을 수행 (Suffle을 통해 데이터를 전달받은 Reducer가 Reduce과정을 수행하기 전 전처리)

5. Reduce
사용자에 의해 정의된 연산을 수행

    ##### *MapReduce를 사용한 Word Count 예제*
    ![예제](https://www.researchgate.net/profile/K_Srinivasa/publication/281768670/figure/fig3/AS:282303059251209@1444317702935/Different-phases-of-map-reduce-in-word-count-example.png)

###### - &nbsp;[참고자료 1](https://m.blog.naver.com/PostView.nhn?blogId=alice_k106&logNo=220462251435&proxyReferer=https%3A%2F%2Fwww.google.com%2F)

---